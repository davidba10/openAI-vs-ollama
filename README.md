# openAI-vs-ollama

# GPT-4o vs Modelos Locales Gratuitos - ComparaciÃ³n Real

ComparaciÃ³n exhaustiva entre GPT-4o y modelos de IA locales completamente gratuitos en 6 pruebas del mundo real.

## ğŸ¥ Video del Experimento

[Ver video completo en YouTube](URL_DE_TU_VIDEO)

## ğŸ“Š Resumen de Resultados

| Prueba | GPT-4o | Mejor Local | Diferencia | Ganador |
|--------|--------|-------------|------------|---------|
| 1. CÃ³digo Python | 96/100 | Qwen 7B: 98/100 | +2 | ğŸŸ¢ Local |
| 2. Sentimiento | 98/100 | Mistral 7B: 98/100 | 0 | ğŸŸ¡ Empate |
| 3. ExtracciÃ³n Datos | 87/100 | Qwen 14B: 82/100 | -5 | ğŸ”´ GPT-4o |
| 4. Servicio Cliente | 95/100 | Llama 8B: 88/100 | -7 | ğŸ”´ GPT-4o |
| 5. PDFs | 92/100 | Mixtral 8x7B: 85/100 | -7 | ğŸ”´ GPT-4o |
| 6. Workflow Completo | 94/100 | Llama 70B: 90/100 | -4 | ğŸ”´ GPT-4o |

**Score Final: GPT-4o 4 - Locales 2**

**Pero:** Para tareas especÃ­ficas con el modelo correcto, los locales son iguales o mejores.

## ğŸ’° AnÃ¡lisis de Costos

### Escenario: 10,000 requests/mes

**Solo GPT-4o:**
- Costo mensual: $50
- Costo anual: $600

**Estrategia HÃ­brida:**
- 60% Modelos locales: $0
- 30% GPT-4o mini: $1.50
- 10% GPT-4o (crÃ­tico): $5
- **Total: $6.50/mes = $78/aÃ±o**
- **Ahorro: $522/aÃ±o (87%)**

## ğŸ› ï¸ Stack TecnolÃ³gico

- **n8n**: Plataforma de automatizaciÃ³n open source
- **Ollama**: Runtime para modelos locales
- **OpenAI API**: Para GPT-4o
- **Python 3.10+**: Scripts de anÃ¡lisis
- **Claude API**: GeneraciÃ³n de evaluadores

## ğŸ¤– Modelos Utilizados

### GPT-4o
- ParÃ¡metros: 1-2 Trillones (estimado)
- Costo: $0.005/1K tokens input, $0.015/1K output
- Velocidad: ~4-6 segundos

### Modelos Locales

**Para CÃ³digo:**
- Qwen 2.5 Coder 7B
- DeepSeek Coder 6.7B

**Para Lenguaje Natural:**
- Llama 3.1 8B
- Mistral 7B Instruct

**Para Tareas Complejas:**
- Qwen 2.5 14B
- Mixtral 8x7B

**Para Workflows:**
- Llama 3.1 70B

## ğŸ“‹ Las 6 Pruebas

### Prueba 1: GeneraciÃ³n de CÃ³digo Python

**Objetivo:** Crear funciÃ³n para calcular distancia euclidiana con:
- Docstring completo
- Type hints
- Error handling
- CÃ³digo limpio y eficiente

**Prompt:**
```
Genera una funciÃ³n Python que calcule la distancia euclidiana entre dos puntos en un plano 2D.

REQUISITOS OBLIGATORIOS:
1. Nombre: "euclidean_distance"
2. ParÃ¡metros: point1, point2 (tuplas con x, y)
3. Docstring completo
4. Type hints para parÃ¡metros y retorno
5. Manejo de errores (validaciÃ³n de inputs)
6. Retornar float con distancia

FÃ“RMULA: distancia = âˆš[(x2 - x1)Â² + (y2 - y1)Â²]

Responde ÃšNICAMENTE en JSON:
{
  "code": "cÃ³digo completo (usar \\n para saltos)",
  "explanation": "breve explicaciÃ³n",
  "features": {
    "has_docstring": true/false,
    "has_type_hints": true/false,
    "has_error_handling": true/false,
    "function_name": "euclidean_distance"
  },
  "complexity": "bÃ¡sica/intermedia/avanzada",
  "estimated_lines": nÃºmero
}

NO markdown, NO ```json, solo JSON puro.
```

**Resultado:** ğŸŸ¢ Qwen ganÃ³ (98 vs 96)

---

### Prueba 2: AnÃ¡lisis de Sentimiento

**Objetivo:** Clasificar 5 tweets como positivo, negativo o neutral con:
- ClasificaciÃ³n precisa
- Nivel de confianza
- Razones especÃ­ficas

**Prompt:**
```
Analiza el sentimiento de los siguientes 5 tweets y clasifÃ­calos como positivo, negativo o neutral.

TWEETS:
1. "Â¡IncreÃ­ble producto! SuperÃ³ mis expectativas ğŸ‰"
2. "El servicio al cliente fue terrible, nunca mÃ¡s compro aquÃ­"
3. "El paquete llegÃ³ hoy. Todo en orden."
4. "No sÃ© si recomendarlo, tiene pros y contras"
5. "ESTAFA TOTAL. Me timaron. Eviten esta empresa"

INSTRUCCIONES:
- Clasifica cada tweet: positivo/negativo/neutral
- Asigna confianza (0.0-1.0)
- RazÃ³n breve (10-30 palabras) mencionando palabras clave
- Calcula resumen con totales

Responde en JSON:
{
  "resultados": [
    {
      "tweet_id": 1,
      "sentimiento": "positivo/negativo/neutral",
      "confianza": 0.0-1.0,
      "razon": "explicaciÃ³n especÃ­fica"
    }
  ],
  "resumen": {
    "positivos": nÃºmero,
    "negativos": nÃºmero,
    "neutrales": nÃºmero
  }
}

NO markdown, solo JSON puro.
```

**Resultado:** ğŸŸ¡ Empate tÃ©cnico - GPT-4o y Mistral (98/100)

---

### Prueba 3: ExtracciÃ³n de Datos Estructurados

**Objetivo:** Extraer informaciÃ³n de 3 emails desordenados a JSON estructurado.

**Prompt:**
```
Extrae informaciÃ³n estructurada de los siguientes 3 correos electrÃ³nicos de clientes.

CORREOS:

--- EMAIL 1 ---
De: maria.garcia@email.com
Fecha: 15 de marzo de 2024
Asunto: Pedido urgente - Laptop HP

Hola,

Necesito cotizaciÃ³n para:
- 5 laptops HP ProBook 450 G10
- 2 monitores Dell 27" 4K
- 1 licencia Microsoft Office 365 Business (10 usuarios)

Presupuesto mÃ¡ximo: 8,500 EUR
Fecha lÃ­mite de entrega: 30 de marzo
MÃ©todo de pago preferido: Transferencia bancaria

Saludos,
MarÃ­a GarcÃ­a
Empresa: TechSolutions SL
TelÃ©fono: +34 91 123 4567

--- EMAIL 2 ---
De: juan.lopez@startup.io
Fecha: 18 de marzo de 2024
Asunto: Re: Consulta sobre servidores

Buenas tardes,

DespuÃ©s de revisar las opciones, me gustarÃ­a proceder con:
- 2x Servidor Dell PowerEdge R740 (32GB RAM, 2TB SSD)
- InstalaciÃ³n y configuraciÃ³n incluida
- Soporte tÃ©cnico por 1 aÃ±o

El proyecto tiene un presupuesto de 12,000-15,000 EUR.
Necesitamos instalaciÃ³n antes del 15 de abril.
Podemos pagar 50% por adelantado y 50% al finalizar.

Empresa: InnovaStart
CIF: B98765432
Contacto: Juan LÃ³pez (CTO)
Tel: +34 93 987 6543

--- EMAIL 3 ---
De: ana.martinez@pyme.es
Fecha: 20 de marzo de 2024
Asunto: RenovaciÃ³n equipos oficina

Hola equipo,

Para la renovaciÃ³n de nuestra oficina necesitamos:
- 8 ordenadores de sobremesa (i5, 16GB RAM, 512GB SSD)
- 8 monitores de 24 pulgadas
- Teclados y ratones inalÃ¡mbricos
- 1 impresora multifunciÃ³n lÃ¡ser color

No tenemos prisa, puede ser entrega en mayo.
Presupuesto aproximado: 6000â‚¬
Forma de pago: Contrareembolso o tarjeta

Ana MartÃ­nez
Directora Administrativa
Comercial del Norte SL
ana.martinez@pyme.es
Tel: 987 654 321

INSTRUCCIONES:
- Extrae la informaciÃ³n de cada email en formato estructurado
- Identifica: cliente, fecha, productos/servicios, cantidades, presupuesto, fecha entrega, mÃ©todo pago, contacto
- Si algÃºn dato no estÃ¡ presente, usa null
- Calcula el presupuesto total sumando todos los emails
- Clasifica cada pedido por urgencia (alta/media/baja) segÃºn la fecha de entrega

Responde ÃšNICAMENTE en formato JSON con esta estructura exacta:
{
  "pedidos": [
    {
      "email_id": 1,
      "cliente": {
        "nombre": "nombre completo",
        "empresa": "nombre empresa o null",
        "email": "email",
        "telefono": "telefono o null",
        "cif": "CIF o null"
      },
      "fecha_solicitud": "YYYY-MM-DD",
      "productos": [
        {
          "descripcion": "descripciÃ³n producto",
          "cantidad": nÃºmero,
          "categoria": "hardware/software/servicio"
        }
      ],
      "presupuesto": {
        "minimo": nÃºmero_o_null,
        "maximo": nÃºmero_o_null,
        "moneda": "EUR"
      },
      "fecha_entrega": "YYYY-MM-DD o null",
      "urgencia": "alta/media/baja",
      "metodo_pago": "descripciÃ³n o null",
      "notas": "informaciÃ³n adicional relevante o null"
    }
  ],
  "resumen": {
    "total_pedidos": nÃºmero,
    "presupuesto_total_min": nÃºmero,
    "presupuesto_total_max": nÃºmero,
    "pedidos_urgentes": nÃºmero,
    "categorias": {
      "hardware": nÃºmero_de_items,
      "software": nÃºmero_de_items,
      "servicio": nÃºmero_de_items
    }
  }
}

IMPORTANTE:
- NO uses formato markdown
- NO uses ```json o ```
- SOLO responde con el objeto JSON puro
- Todos los nÃºmeros deben ser numÃ©ricos, no strings
- Las fechas deben estar en formato ISO (YYYY-MM-DD)
- Calcula correctamente las sumas en el resumen
```

**Resultado:** ğŸ”´ GPT-4o ganÃ³ (87 vs 82)

---

### Prueba 4: Servicio al Cliente

**Objetivo:** Responder a una queja de cliente con empatÃ­a y profesionalismo.

**Prompt:**
```
Eres un agente de atenciÃ³n al cliente de TechStore. Responde al siguiente email de un cliente frustrado.

EMAIL DEL CLIENTE:
De: carlos.ruiz@email.com
Asunto: Problema con mi pedido #TR-2847
Fecha: 20 de marzo de 2024

"Hola,

Hace mÃ¡s de 2 semanas que hice un pedido de un Lenovo ThinkPad X1 Carbon Gen 11 
(pedido #TR-2847) y todavÃ­a no lo he recibido. En la web dice 'En proceso' pero 
no he recibido ninguna actualizaciÃ³n. Necesito el portÃ¡til urgentemente para mi 
nuevo trabajo que empieza el lunes. Â¿QuÃ© estÃ¡ pasando?

Carlos Ruiz"

CONTEXTO INTERNO:
- Hubo un retraso por falta de stock (ya solucionado)
- El producto estÃ¡ listo para envÃ­o maÃ±ana
- Transportista: DHL Express (1-2 dÃ­as de entrega)
- URL de seguimiento: https://techstore.com/tracking/TR-2847
- Puedes ofrecer 10% descuento en prÃ³xima compra

INSTRUCCIONES:
- SÃ© empÃ¡tico y reconoce la frustraciÃ³n del cliente
- Explica brevemente la causa del retraso
- Ofrece soluciÃ³n concreta con timeframe
- Incluye informaciÃ³n de seguimiento
- Ofrece compensaciÃ³n
- MantÃ©n tono profesional pero cÃ¡lido

Responde en JSON:
{
  "asunto": "Asunto del email de respuesta",
  "cuerpo": "Texto completo de la respuesta (usar \\n para saltos de lÃ­nea)",
  "tono": "descripciÃ³n del tono usado",
  "compensacion_ofrecida": "quÃ© compensaciÃ³n ofreciste",
  "problema_resuelto": true/false,
  "tiempo_respuesta_estimado": "estimaciÃ³n de cuÃ¡ndo recibirÃ¡ el producto"
}

NO markdown, solo JSON puro.
```

**Resultado:** ğŸ”´ GPT-4o ganÃ³ (95 vs 88)

---

### Prueba 5: Procesamiento de PDFs

*(Prompt disponible en el repositorio - similar estructura)*

**Resultado:** ğŸ”´ GPT-4o ganÃ³ (92 vs 85)

---

### Prueba 6: Workflow Completo End-to-End

*(Prompt disponible en el repositorio - combina mÃºltiples tareas)*

**Resultado:** ğŸ”´ GPT-4o ganÃ³ (94 vs 90)

## ğŸš€ InstalaciÃ³n y Uso

### Prerrequisitos
```bash
# Hardware recomendado
- GPU: 8GB VRAM mÃ­nimo (para modelos 7B-14B)
- RAM: 32GB (para Mixtral 8x7B)
- Disco: 60GB libres

# Software
- Python 3.10+
- Ollama
- n8n (opcional)
- Node.js 18+ (para n8n)
```

### 1. Instalar Ollama
```bash
# Linux/Mac
curl -fsSL https://ollama.com/install.sh | sh

# Windows
# Descargar desde https://ollama.com/download
```

### 2. Descargar Modelos
```bash
# Para cÃ³digo (Prueba 1)
ollama pull qwen2.5-coder:7b
ollama pull deepseek-coder:6.7b-instruct

# Para sentimiento (Prueba 2)
ollama pull llama3.1:8b
ollama pull mistral:7b-instruct-v0.3

# Para datos (Prueba 3)
ollama pull qwen2.5:14b-instruct-q4_K_M
ollama pull mixtral:8x7b-instruct-v0.1-q4_K_M

# Para servicio al cliente (Prueba 4)
# Reutiliza llama3.1:8b y mistral:7b-instruct-v0.3

# Tiempo total descarga: ~30-45 min
# Espacio total: ~55GB
```

### 3. Clonar Repositorio
```bash
git clone https://github.com/tuusuario/gpt4o-vs-local-models.git
cd gpt4o-vs-local-models
```

### 4. Instalar Dependencias
```bash
pip install -r requirements.txt
```

### 5. Configurar API Keys
```bash
# Crear archivo .env
cp .env.example .env

# Editar .env y aÃ±adir:
OPENAI_API_KEY=tu_api_key_aqui
ANTHROPIC_API_KEY=tu_api_key_aqui  # Opcional, para evaluadores
```

### 6. Ejecutar Pruebas
```bash
# Prueba 1: CÃ³digo
python scripts/test_1_code.py

# Prueba 2: Sentimiento
python scripts/test_2_sentiment.py

# Prueba 3: ExtracciÃ³n
python scripts/test_3_extraction.py

# Prueba 4: Servicio
python scripts/test_4_customer_service.py

# Ejecutar todas
python run_all_tests.py
```

## ğŸ“ Estructura del Proyecto
```
gpt4o-vs-local-models/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ prompt_1_code.txt
â”‚   â”œâ”€â”€ prompt_2_sentiment.txt
â”‚   â”œâ”€â”€ prompt_3_extraction.txt
â”‚   â”œâ”€â”€ prompt_4_customer_service.txt
â”‚   â”œâ”€â”€ prompt_5_pdf.txt
â”‚   â””â”€â”€ prompt_6_workflow.txt
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ code_battle_analysis.py
â”‚   â”œâ”€â”€ sentiment_battle_analysis.py
â”‚   â”œâ”€â”€ data_extraction_analysis.py
â”‚   â”œâ”€â”€ customer_service_analysis.py
â”‚   â””â”€â”€ run_all_tests.py
â”œâ”€â”€ n8n_workflows/
â”‚   â”œâ”€â”€ workflow_test_1.json
â”‚   â”œâ”€â”€ workflow_test_2.json
â”‚   â””â”€â”€ ...
â””â”€â”€ results/
    â”œâ”€â”€ test_1_results.json
    â”œâ”€â”€ test_2_results.json
    â””â”€â”€ ...
```

## ğŸ¯ FilosofÃ­a del Experimento

### Por quÃ© diferentes modelos para cada prueba

No usÃ© el mismo modelo local para todas las pruebas porque:

1. **EspecializaciÃ³n importa**: Un modelo entrenado en cÃ³digo serÃ¡ mejor en programaciÃ³n
2. **ProducciÃ³n real**: AsÃ­ es como usarÃ­as modelos en un entorno real
3. **Evita cherry-picking**: Si varios modelos especializados compiten bien, valida la estrategia
4. **Optimiza recursos**: Modelos pequeÃ±os para tareas simples, grandes para complejas

### EvaluaciÃ³n Imparcial

Para evitar sesgos:
- UsÃ© Claude para generar scripts de evaluaciÃ³n automÃ¡tica
- Criterios objetivos y puntuaciÃ³n numÃ©rica
- Claude no sabÃ­a quÃ© modelo generÃ³ cada output
- Scripts disponibles para replicar

## ğŸ’¡ Conclusiones Clave

### âœ… CuÃ¡ndo usar Modelos Locales

- **CÃ³digo simple a medio**: Qwen Coder es igual o mejor
- **ClasificaciÃ³n/anÃ¡lisis bÃ¡sico**: Llama/Mistral son excelentes
- **Alto volumen**: El ahorro justifica la configuraciÃ³n inicial
- **Privacidad crÃ­tica**: Datos nunca salen de tu servidor
- **Prototipado rÃ¡pido**: Iteraciones gratis

### âœ… CuÃ¡ndo usar GPT-4o

- **Tareas mission-critical**: Servicio al cliente, legal, mÃ©dico
- **Contextos muy largos**: GPT-4o tiene 128K tokens
- **Razonamiento complejo**: Mejor en multi-step reasoning
- **Sin recursos tÃ©cnicos**: No quieres configurar servidores
- **MÃ¡xima fiabilidad**: Menos errores, mÃ¡s consistente

### ğŸ¯ Estrategia Recomendada: HÃ­brido
```
60% â†’ Modelos locales (tareas rutinarias)
30% â†’ GPT-4o mini (equilibrio precio/calidad)
10% â†’ GPT-4o full (casos crÃ­ticos)

Ahorro: 87% vs usar solo GPT-4o
```

## ğŸ“Š Datos Completos

Todos los outputs reales, puntuaciones detalladas y anÃ¡lisis estÃ¡n en:
- `/results/detailed_scores.json`
- `/results/analysis_reports.md`

## ğŸ¤ Contribuir

Â¿Quieres aÃ±adir mÃ¡s pruebas o modelos?

1. Fork el repositorio
2. Crea tu branch (`git checkout -b feature/nueva-prueba`)
3. Commit tus cambios (`git commit -m 'AÃ±ade prueba X'`)
4. Push al branch (`git push origin feature/nueva-prueba`)
5. Abre un Pull Request

## ğŸ“œ Licencia

MIT License - Ãšsalo libremente, con atribuciÃ³n

## ğŸ‘¤ Autor

**David BeltrÃ¡n**
- YouTube: [@DavidBeltran](TU_CANAL)
- GitHub: [@tuusuario](https://github.com/tuusuario)
- LinkedIn: [Tu LinkedIn](TU_LINKEDIN)

Documentando mi camino a 10,000 horas en IA ğŸš€

## â­ Apoya el Proyecto

Si este experimento te ha sido Ãºtil:
- â­ Dale estrella al repo
- ğŸ”„ CompÃ¡rtelo con tu equipo
- ğŸ“¹ SuscrÃ­bete al canal
- ğŸ’¬ DÃ©jame saber quÃ© otras comparaciones quieres ver

---

**Ãšltima actualizaciÃ³n:** Diciembre 2024
